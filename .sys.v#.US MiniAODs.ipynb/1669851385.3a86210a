{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "430a400b",
   "metadata": {},
   "source": [
    "Let's review MINIAOD(SIM) usage on US disk sites (T1 and T2).\n",
    "\n",
    "We need a breakdown of\n",
    "\n",
    "Campaign name | size on US disks | last accessed\n",
    "\n",
    "After that, we can choose where to put the cut and lift the rules for unused or super old campaigns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47a93044",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T23:22:08.067789Z",
     "start_time": "2022-11-30T23:22:07.540697Z"
    }
   },
   "outputs": [],
   "source": [
    "#import\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9561170c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T23:22:38.987377Z",
     "start_time": "2022-11-30T23:22:38.984680Z"
    }
   },
   "outputs": [],
   "source": [
    "TODAY = datetime.today()\n",
    "TODAY = TODAY - timedelta(days=1)# uncomment to use YESTERDAY as today\n",
    "TODAY = TODAY.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81dbd2e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T23:22:39.264073Z",
     "start_time": "2022-11-30T23:22:39.261249Z"
    }
   },
   "outputs": [],
   "source": [
    "#pandas display settings\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca728d0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T23:22:39.670960Z",
     "start_time": "2022-11-30T23:22:39.667957Z"
    }
   },
   "outputs": [],
   "source": [
    "#HDFS import paths\n",
    "\n",
    "HDFS_RUCIO_CONTENTS = \"/project/awg/cms/rucio/{}/contents/part*.avro\".format(TODAY)\n",
    "HDFS_RUCIO_REPLICAS = \"/project/awg/cms/rucio/{}/replicas/part*.avro\".format(TODAY)\n",
    "HDFS_RUCIO_DIDS     = \"/project/awg/cms/rucio/{}/dids/part*.avro\".format(TODAY)\n",
    "HDFS_RUCIO_LOCKS    = \"/project/awg/cms/rucio/{}/locks/part*.avro\".format(TODAY)\n",
    "HDFS_RUCIO_RSES     = \"/project/awg/cms/rucio/{}/rses/part*.avro\".format(TODAY)\n",
    "HDFS_RUCIO_RULES     = \"/project/awg/cms/rucio/{}/rules/part*.avro\".format(TODAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c668423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12a43b73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T23:22:43.014037Z",
     "start_time": "2022-11-30T23:22:41.048448Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_rses = spark.read.format('avro').load(HDFS_RUCIO_RSES)\\\n",
    "    .withColumn('rse_id', F.lower(F.hex(F.col('ID'))))\\\n",
    "    .withColumnRenamed('RSE', 'rse_name')\\\n",
    "    .withColumnRenamed('RSE_TYPE', 'rse_type')\\\n",
    "    .select(['rse_name', 'rse_id', 'rse_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c326978",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T23:22:45.411079Z",
     "start_time": "2022-11-30T23:22:45.363900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the list of desired Rses - T1 and T2 Rses at US sites\n",
    "\n",
    "\n",
    "df_disk_rses = df_rses.filter(\n",
    "                            ( ~ F.col('rse_name').contains(\"_Tape\") ) & \\\n",
    "                            ( ~ F.col('rse_name').contains(\"T3_\") ) & \\\n",
    "                            ( ~ F.col('rse_name').contains(\"_Test\") ) & \\\n",
    "                            ( ~ F.col('rse_name').contains(\"_Temp\") ) & \\\n",
    "                            ( ~ F.col('rse_name').contains(\"_Ceph\") )\n",
    "                           )\n",
    "\n",
    "\n",
    "SITE = \"US\" #T2_CH_CERN\n",
    "\n",
    "df_us_disk_rses = df_disk_rses.filter(F.col('rse_name').contains(SITE))\n",
    "df_non_us_disk_rses = df_disk_rses.filter(~F.col('rse_name').contains(SITE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3911d8ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T23:22:52.408442Z",
     "start_time": "2022-11-30T23:22:46.760778Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rse_name</th>\n",
       "      <th>rse_id</th>\n",
       "      <th>rse_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T2_US_Caltech</td>\n",
       "      <td>a0c1b4ce18324a9d80ea60f16e8b485d</td>\n",
       "      <td>DISK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2_US_Nebraska</td>\n",
       "      <td>a6981dee6ed14b7c8c1b0e9fe7644401</td>\n",
       "      <td>DISK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T2_US_Wisconsin</td>\n",
       "      <td>80f94591a3154d1e847cd784b08a0dd1</td>\n",
       "      <td>DISK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T2_US_Florida</td>\n",
       "      <td>9cab8c2f425b4de8ba03a4f430722ffc</td>\n",
       "      <td>DISK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T2_US_Purdue</td>\n",
       "      <td>be0c1696016e4297a1573425d4a9b0a6</td>\n",
       "      <td>DISK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T2_US_UCSD</td>\n",
       "      <td>62b59a7c95194dc39844f99d5d7e61bf</td>\n",
       "      <td>DISK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T2_US_MIT</td>\n",
       "      <td>2694b6bd279f4baa890f5abbe66351d2</td>\n",
       "      <td>DISK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T1_US_FNAL_Disk</td>\n",
       "      <td>087ee3383b9d45f6b31814af07b2c56d</td>\n",
       "      <td>DISK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>T2_US_Vanderbilt</td>\n",
       "      <td>5eeec458c03d4bd18ef70a3cad0a31af</td>\n",
       "      <td>DISK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           rse_name                            rse_id rse_type\n",
       "0     T2_US_Caltech  a0c1b4ce18324a9d80ea60f16e8b485d     DISK\n",
       "1    T2_US_Nebraska  a6981dee6ed14b7c8c1b0e9fe7644401     DISK\n",
       "2   T2_US_Wisconsin  80f94591a3154d1e847cd784b08a0dd1     DISK\n",
       "3     T2_US_Florida  9cab8c2f425b4de8ba03a4f430722ffc     DISK\n",
       "4      T2_US_Purdue  be0c1696016e4297a1573425d4a9b0a6     DISK\n",
       "5        T2_US_UCSD  62b59a7c95194dc39844f99d5d7e61bf     DISK\n",
       "6         T2_US_MIT  2694b6bd279f4baa890f5abbe66351d2     DISK\n",
       "7   T1_US_FNAL_Disk  087ee3383b9d45f6b31814af07b2c56d     DISK\n",
       "8  T2_US_Vanderbilt  5eeec458c03d4bd18ef70a3cad0a31af     DISK"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us_disk_rses.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9a615fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T23:22:53.619234Z",
     "start_time": "2022-11-30T23:22:52.410224Z"
    }
   },
   "outputs": [],
   "source": [
    "# MINIAOD(SIM) files with locks\n",
    "\n",
    "df_locks = spark.read.format('avro').load(HDFS_RUCIO_LOCKS) \\\n",
    "    .filter(F.col(\"STATE\") == 'O') \\\n",
    "    .withColumnRenamed(\"NAME\", \"file_name\") \\\n",
    "    .withColumn('file_size', F.col('BYTES').cast(T.LongType())) \\\n",
    "    .withColumn('rule', F.lower(F.hex(F.col('RULE_ID')))) \\\n",
    "    .withColumn('rse_id', F.lower(F.hex(F.col('RSE_ID')))) \\\n",
    "    .withColumn(\"created_date\", F.from_unixtime(F.col('created_at')/1000).cast(T.DateType())) \\\n",
    "    .withColumn(\"rule_age_days\", F.datediff(F.current_date(), F.col('created_date'))) \\\n",
    "    .select([\"file_name\", \"file_size\", \"rule\", \"rse_id\", \"created_date\", \"rule_age_days\"])\n",
    "\n",
    "\n",
    "df_locks_miniaods = df_locks.filter(F.col('file_name').contains('MINIAOD'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aeb9509d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T23:22:59.774265Z",
     "start_time": "2022-11-30T23:22:59.772320Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_locks.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f3666dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T23:23:01.622416Z",
     "start_time": "2022-11-30T23:23:01.521276Z"
    }
   },
   "outputs": [],
   "source": [
    "df_locks_miniaod_us = df_us_disk_rses.alias(\"us_rses\")\\\n",
    "                            .join(df_locks_miniaods.alias(\"locks\"), F.col(\"us_rses.rse_id\")==F.col(\"locks.rse_id\"))\\\n",
    "                            .select([\"us_rses.rse_name\", \"us_rses.rse_id\", \"locks.file_name\", \"locks.file_size\", \"locks.rule\"])\n",
    "\n",
    "df_locks_miniaod_non_us = df_non_us_disk_rses.alias(\"non_us_rses\")\\\n",
    "                            .join(df_locks_miniaods.alias(\"locks\"), F.col(\"non_us_rses.rse_id\")==F.col(\"locks.rse_id\"))\\\n",
    "                            .select([\"non_us_rses.rse_name\", \"non_us_rses.rse_id\", \"locks.file_name\", \"locks.file_size\", \"locks.rule\"])\n",
    "\n",
    "df_locks_miniaod_all = df_rses.alias(\"all_rses\")\\\n",
    "                            .join(df_locks_miniaods.alias(\"locks\"), F.col(\"all_rses.rse_id\")==F.col(\"locks.rse_id\"))\\\n",
    "                            .select([\"all_rses.rse_name\", \"all_rses.rse_id\", \"locks.file_name\", \"locks.file_size\", \"locks.rule\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9bc1e30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T23:23:06.919599Z",
     "start_time": "2022-11-30T23:23:06.917344Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_locks_miniaod_non_us.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "514f0920",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T23:23:07.571963Z",
     "start_time": "2022-11-30T23:23:07.569552Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_locks_miniaod_us.filter(F.col(\"file_name\").contains(\"RunIISummer20UL18MiniAODv2\")).dropDuplicates([\"file_name\"]).groupby().sum(\"file_size\").show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3af9c7a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T23:23:09.288016Z",
     "start_time": "2022-11-30T23:23:08.733817Z"
    }
   },
   "outputs": [],
   "source": [
    "#Get file and block name maps\n",
    "\n",
    "df_file_block_map = spark.read.format('avro').load(HDFS_RUCIO_CONTENTS)\\\n",
    "                    .filter(F.col('CHILD_TYPE')=='F')\\\n",
    "                    .withColumnRenamed('NAME', 'block_name')\\\n",
    "                    .withColumnRenamed('CHILD_NAME', 'file_name')\\\n",
    "                    .select(['block_name', \"file_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a25d7d12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T23:23:11.076191Z",
     "start_time": "2022-11-30T23:23:11.039679Z"
    }
   },
   "outputs": [],
   "source": [
    "df_blocks_miniaod_us = df_locks_miniaod_us.alias(\"mini_files\")\\\n",
    "                                    .join(df_file_block_map.alias(\"file_block_map\"),\n",
    "                                         F.col(\"mini_files.file_name\")==F.col(\"file_block_map.file_name\")\n",
    "                                         )\\\n",
    "                                    .withColumnRenamed('rse_name', 'us_disk_rse')\\\n",
    "                                    .select([\"us_disk_rse\", \"mini_files.rse_id\", \"mini_files.file_name\", \"mini_files.file_size\", \"mini_files.rule\", \"file_block_map.block_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81d71945",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T23:23:11.993117Z",
     "start_time": "2022-11-30T23:23:11.497640Z"
    }
   },
   "outputs": [],
   "source": [
    "df_block_dataset_map = spark.read.format('avro').load(HDFS_RUCIO_CONTENTS)\\\n",
    "                    .filter(F.col('CHILD_TYPE')=='D')\\\n",
    "                    .withColumnRenamed('NAME', 'dataset_name')\\\n",
    "                    .withColumnRenamed('CHILD_NAME', 'block_name')\\\n",
    "                    .select(['dataset_name', \"block_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77bfa233",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T23:23:20.330184Z",
     "start_time": "2022-11-30T23:23:20.232770Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#group by campaign, tier etc\n",
    "\n",
    "df_miniaod_us_campaign = df_blocks_miniaod_us.na.fill(0)\\\n",
    "                                    .withColumn('dataset_name', F.split(F.col('block_name'), '#').getItem(0))\\\n",
    "                                    .withColumn('tier', F.split(F.col('dataset_name'), '/').getItem(3))\\\n",
    "                                    .withColumn('brute_campaign', F.split(F.col('dataset_name'), '/').getItem(2))\\\n",
    "                                    .withColumn('short_campaign', F.split(F.col('brute_campaign'), '-').getItem(0))\\\n",
    "                                    .withColumn('campaign',\n",
    "                                               F.when(F.col(\"tier\")==\"MINIAOD\", F.col(\"brute_campaign\"))\\\n",
    "                                                .otherwise(F.col(\"short_campaign\"))\n",
    "                                               )\\\n",
    "                                    .dropDuplicates([\"file_name\"])\\\n",
    "                                    .select([\"campaign\", \"file_name\", \"dataset_name\", \"file_size\"])\n",
    "#                                     .withColumn(\"accessed_at_date\", F.from_unixtime(F.col('accessed_at')/1000).cast(T.DateType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdfd66f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T23:23:25.886743Z",
     "start_time": "2022-11-30T23:23:25.829694Z"
    }
   },
   "outputs": [],
   "source": [
    "X = 30\n",
    "top_X_campaigns = df_miniaod_us_campaign\\\n",
    "             .groupby(['campaign'])\\\n",
    "             .agg(F.sum(\"file_size\").alias(\"campaign_size\"))\\\n",
    "             .sort(F.col(\"campaign_size\").desc())\\\n",
    "             .limit(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "914b1947",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T23:24:15.324140Z",
     "start_time": "2022-11-30T23:23:28.487140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+----------------+\n",
      "|campaign                      |campaign_size   |\n",
      "+------------------------------+----------------+\n",
      "|RunIISummer20UL18MiniAODv2    |1939205289593476|\n",
      "|RunIIAutumn18MiniAOD          |1765960847851998|\n",
      "|RunIIFall17MiniAODv2          |1755784799488829|\n",
      "|RunIISummer20UL17MiniAODv2    |1545908276160323|\n",
      "|RunIISummer20UL18MiniAOD      |1101781194019679|\n",
      "|RunIISummer16MiniAODv3        |1011595089653944|\n",
      "|RunIISummer20UL17MiniAOD      |883905093052120 |\n",
      "|RunIISummer20UL16MiniAODv2    |809806886741066 |\n",
      "|RunIISummer20UL16MiniAODAPVv2 |736467526258080 |\n",
      "|RunIISummer16MiniAODv2        |662852568331200 |\n",
      "|Run2018D-05May2019promptD-v1  |642458545376894 |\n",
      "|Run2018D-UL2018_MiniAODv2-v1  |597111130349395 |\n",
      "|RunIISummer20UL16MiniAOD      |509919334113197 |\n",
      "|RunIISummer20UL16MiniAODAPV   |444805461807943 |\n",
      "|Run2022F-PromptReco-v1        |330138059157485 |\n",
      "|HIRun2018A-PbPb18_MiniAODv1-v1|223296483229525 |\n",
      "|Run3Summer21MiniAOD           |209381472128320 |\n",
      "|Run3Winter22MiniAOD           |146957265374897 |\n",
      "|Run2022C-PromptReco-v1        |141415079691940 |\n",
      "|Run2018D-PromptReco-v2        |133736254090284 |\n",
      "|Run2018A-UL2018_MiniAODv2-v1  |127149466336034 |\n",
      "|Run2022E-PromptReco-v1        |117031566283437 |\n",
      "|Run2018B-05May2019-v2         |109478139836015 |\n",
      "|Run2018B-UL2018_MiniAODv2-v1  |107025240597159 |\n",
      "|Run2018D-15Feb2022_UL2018-v1  |103219436930491 |\n",
      "|Run2018C-UL2018_MiniAODv2-v1  |100140324701733 |\n",
      "|Run2018C-05May2019-v1         |100096342797526 |\n",
      "|Run2018A-05May2019-v1         |99627999921488  |\n",
      "|Run3Winter21DRMiniAOD         |73145663824010  |\n",
      "|HINPbPbSpring21MiniAOD        |71576492737382  |\n",
      "+------------------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_X_campaigns.show(X, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f76273a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T23:24:41.588548Z",
     "start_time": "2022-11-30T23:24:15.325852Z"
    }
   },
   "outputs": [],
   "source": [
    "#get list of campaigns to create datasets analysis for them\n",
    "#get size of each campaign\n",
    "\n",
    "temp_d = top_X_campaigns.toPandas().to_dict()\n",
    "campaign_size_dict = {}\n",
    "for i in range(X):\n",
    "    campaign_size_dict[temp_d['campaign'][i]] = temp_d['campaign_size'][i]\n",
    "    \n",
    "campaigns_list = list(campaign_size_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41e117cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T23:24:41.648805Z",
     "start_time": "2022-11-30T23:24:41.589995Z"
    }
   },
   "outputs": [],
   "source": [
    "topX_campaign_files = top_X_campaigns.alias(\"topX\")\\\n",
    "                        .join(\n",
    "                            df_miniaod_us_campaign.alias(\"all\"),\n",
    "                            F.col(\"topX.campaign\")==F.col(\"all.campaign\")\n",
    "                        )\\\n",
    "                        .select([\"topX.campaign\", \"campaign_size\", \"file_name\", \"dataset_name\", \"file_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed9f91ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T23:24:41.705823Z",
     "start_time": "2022-11-30T23:24:41.650977Z"
    }
   },
   "outputs": [],
   "source": [
    "other_locked_replicas_for_topX = topX_campaign_files.alias(\"campaign_files\")\\\n",
    "                            .join(\n",
    "                                df_locks_miniaod_all.alias(\"replica\"),\n",
    "                                F.col(\"campaign_files.file_name\")==F.col(\"replica.file_name\")\n",
    "                            )\\\n",
    "                            .select([\"campaign\", \"campaign_size\", \"dataset_name\", \"replica.file_size\", \"rse_name\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c0880bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T23:24:41.762191Z",
     "start_time": "2022-11-30T23:24:41.707255Z"
    }
   },
   "outputs": [],
   "source": [
    "non_us_disk_replicas_for_topX = topX_campaign_files.alias(\"campaign_files\")\\\n",
    "                            .join(\n",
    "                                df_locks_miniaod_non_us.alias(\"non_us_replica\"),\n",
    "                                F.col(\"campaign_files.file_name\")==F.col(\"non_us_replica.file_name\")\n",
    "                            )\\\n",
    "                            .select([\"campaign\", \"campaign_size\", \"dataset_name\", \"non_us_replica.file_size\", \"rse_name\", \"non_us_replica.file_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "458ba190",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T23:24:41.928407Z",
     "start_time": "2022-11-30T23:24:41.763525Z"
    }
   },
   "outputs": [],
   "source": [
    "#Assumption - if a file from a dataset is on tape then other files of the datasets are also on tape\n",
    "#Assumptioon: Datasets are fully replicated at US disk sites\n",
    "\n",
    "\n",
    "us_dataset_file_count = topX_campaign_files\\\n",
    "                            .dropDuplicates([\"file_name\"])\\\n",
    "                            .groupby(\"dataset_name\")\\\n",
    "                            .agg(\n",
    "                                    F.count(F.col(\"file_name\")).alias(\"file_count_us\"),\n",
    "                                    F.sum(\"file_size\").alias(\"dataset_size\")\n",
    "                                )\n",
    "\n",
    "non_us_dataset_file_count = non_us_disk_replicas_for_topX\\\n",
    "                            .dropDuplicates([\"file_name\"])\\\n",
    "                            .groupby(\"dataset_name\")\\\n",
    "                            .agg(F.count(F.col(\"file_name\")).alias(\"file_count_non_us\"))\n",
    "\n",
    "percent_locked_to_non_us_rses = us_dataset_file_count.alias(\"us_count\")\\\n",
    "                                                    .join(\n",
    "                                                            non_us_dataset_file_count.alias(\"non_us_count\"),\n",
    "                                                            F.col(\"us_count.dataset_name\") == F.col(\"non_us_count.dataset_name\"),\n",
    "                                                            \"left\"\n",
    "                                                        )\\\n",
    "                                                    .select([\"us_count.dataset_name\", \"file_count_us\", \"file_count_non_us\", \"us_count.dataset_size\"])\\\n",
    "                                                    .na.fill(0)\\\n",
    "                                                    .withColumn(\"percent_locked_other_sites\", 100*(F.col(\"file_count_non_us\")/F.col(\"file_count_us\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48497694",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-29T08:31:01.709103Z",
     "start_time": "2022-11-29T08:31:01.662729Z"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f19f0b4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-11-30T23:23:46.742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/01 00:35:57 ERROR TransportClient: Failed to send RPC RPC 9173177216285664534 to /188.185.9.1:4876: io.netty.channel.StacklessClosedChannelException\n",
      "io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n",
      "22/12/01 00:35:57 ERROR TransportClient: Failed to send RPC RPC 9106943561727589467 to /188.185.9.1:41746: io.netty.channel.StacklessClosedChannelException\n",
      "io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n",
      "22/12/01 00:35:57 ERROR TransportClient: Failed to send RPC RPC 9001630839489218616 to /188.185.9.1:52908: io.netty.channel.StacklessClosedChannelException\n",
      "io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n",
      "22/12/01 00:35:57 ERROR TransportResponseHandler: Still have 1 requests outstanding when connection from /188.185.9.1:25179 is closed\n",
      "22/12/01 00:35:57 ERROR TransportClient: Failed to send RPC RPC 8181072796321925092 to /188.185.9.1:58557: io.netty.channel.StacklessClosedChannelException\n",
      "io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n",
      "22/12/01 00:35:57 ERROR TransportClient: Failed to send RPC RPC 8245016706645154951 to /188.185.9.1:25179: io.netty.channel.StacklessClosedChannelException\n",
      "io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n",
      "22/12/01 00:35:57 WARN BlockManagerMasterEndpoint: Error trying to remove broadcast 756 from block manager BlockManagerId(27, ithdp2107.cern.ch, 5105, None)\n",
      "java.io.IOException: Connection from /188.185.9.1:25179 closed\n",
      "\tat org.apache.spark.network.client.TransportResponseHandler.channelInactive(TransportResponseHandler.java:147)\n",
      "\tat org.apache.spark.network.server.TransportChannelHandler.channelInactive(TransportChannelHandler.java:117)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)\n",
      "\tat io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)\n",
      "\tat io.netty.handler.timeout.IdleStateHandler.channelInactive(IdleStateHandler.java:277)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)\n",
      "\tat io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)\n",
      "\tat org.apache.spark.network.util.TransportFrameDecoder.channelInactive(TransportFrameDecoder.java:225)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1405)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)\n",
      "\tat io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:901)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe$7.run(AbstractChannel.java:813)\n",
      "\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "22/12/01 00:35:57 WARN BlockManagerMasterEndpoint: Error trying to remove broadcast 756 from block manager BlockManagerId(26, ithdp2107.cern.ch, 5106, None)\n",
      "java.io.IOException: Failed to send RPC RPC 9001630839489218616 to /188.185.9.1:52908: io.netty.channel.StacklessClosedChannelException\n",
      "\tat org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:392)\n",
      "\tat org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:369)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:609)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:999)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:860)\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1367)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:764)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)\n",
      "\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:503)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n",
      "22/12/01 00:35:57 WARN BlockManagerMasterEndpoint: Error trying to remove broadcast 756 from block manager BlockManagerId(12, ithdp2119.cern.ch, 5105, None)\n",
      "java.io.IOException: Failed to send RPC RPC 9106943561727589467 to /188.185.9.1:41746: io.netty.channel.StacklessClosedChannelException\n",
      "\tat org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:392)\n",
      "\tat org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:369)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:609)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:999)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:860)\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1367)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:764)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)\n",
      "\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:503)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n",
      "22/12/01 00:35:57 WARN NettyRpcEnv: Ignored failure: java.io.IOException: Failed to send RPC RPC 8245016706645154951 to /188.185.9.1:25179: io.netty.channel.StacklessClosedChannelException\n",
      "22/12/01 00:35:57 WARN BlockManagerMasterEndpoint: Error trying to remove broadcast 756 from block manager BlockManagerId(28, ithdp2107.cern.ch, 5104, None)\n",
      "java.io.IOException: Failed to send RPC RPC 9173177216285664534 to /188.185.9.1:4876: io.netty.channel.StacklessClosedChannelException\n",
      "\tat org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:392)\n",
      "\tat org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:369)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:609)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:999)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:860)\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1367)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:764)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)\n",
      "\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:503)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n",
      "22/12/01 00:35:57 WARN BlockManagerMasterEndpoint: Error trying to remove broadcast 756 from block manager BlockManagerId(5, ithdp2121.cern.ch, 5103, None)\n",
      "java.io.IOException: Failed to send RPC RPC 8181072796321925092 to /188.185.9.1:58557: io.netty.channel.StacklessClosedChannelException\n",
      "\tat org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:392)\n",
      "\tat org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:369)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:609)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:999)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:860)\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1367)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:764)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)\n",
      "\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:503)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n"
     ]
    }
   ],
   "source": [
    " #insert different dataset name here\n",
    "\n",
    "\n",
    "meta_df = {\n",
    "    \"campaign\": [],\n",
    "    \"campaign_size\": [],\n",
    "    \"sum_dataset_sizes\": [],\n",
    "    \"dataset_on_tape_size\": [],\n",
    "    \"dataset_not_on_tape_size\" :[],\n",
    "    \"total_dataset_count\": [],\n",
    "    \"datasets_on_tape\": [],\n",
    "    \"datasets_not_on_tape\": [],\n",
    "    \"datasets_fully_replicated_at_other_disks\": []\n",
    "}\n",
    "\n",
    "for campaign in campaigns_list:\n",
    "    tape_replicas = other_locked_replicas_for_topX\\\n",
    "                    .filter(F.col(\"campaign\")==campaign)\\\n",
    "                    .groupby([\"dataset_name\"])\\\n",
    "                    .agg(\n",
    "                        F.sum(\"file_size\").alias(\"total_space_occupied\"),\n",
    "                        F.collect_set(F.col(\"rse_name\")).alias(\"rse_set\")\n",
    "                    )\\\n",
    "                    .withColumn(\"rses\", F.concat_ws(\",\", F.col(\"rse_set\")))\\\n",
    "                    .withColumn(\"on_tape\", F.col(\"rses\").contains(\"Tape\"))\\\n",
    "                    .select([\"dataset_name\", \"total_space_occupied\", \"rses\", \"on_tape\"])\n",
    "\n",
    "\n",
    "    tape_rep_dataset_size = tape_replicas.alias(\"tape_rep\")\\\n",
    "                        .join(\n",
    "                                percent_locked_to_non_us_rses.alias(\"dataset_size\"),\n",
    "                                F.col(\"tape_rep.dataset_name\") == F.col(\"dataset_size.dataset_name\")\n",
    "                             )\\\n",
    "                        .select([\"tape_rep.dataset_name\", \"total_space_occupied\", \"rses\", \"on_tape\", \"dataset_size\", \"percent_locked_other_sites\"])\n",
    "\n",
    "\n",
    "    pd_rep = tape_rep_dataset_size.toPandas()\n",
    "\n",
    "    meta_df['campaign'].append(campaign)\n",
    "    meta_df['campaign_size'].append(campaign_size_dict[campaign])\n",
    "    meta_df['total_dataset_count'].append(pd_rep.shape[0])\n",
    "    meta_df['datasets_on_tape'].append(pd_rep[pd_rep.on_tape == True].shape[0])\n",
    "    meta_df['datasets_not_on_tape'].append(pd_rep[pd_rep.on_tape != True].shape[0])\n",
    "    meta_df['sum_dataset_sizes'].append(pd_rep.dataset_size.sum())\n",
    "    meta_df['dataset_on_tape_size'].append(pd_rep[pd_rep.on_tape == True].dataset_size.sum())\n",
    "    meta_df['dataset_not_on_tape_size'].append(pd_rep[pd_rep.on_tape != True].dataset_size.sum())\n",
    "    meta_df['datasets_fully_replicated_at_other_disks'].append(pd_rep[pd_rep.percent_locked_other_sites == 100].shape[0])\n",
    "\n",
    "    pd_rep.to_csv(f\"Campaigns/{SITE}/{campaign}.csv\", index=False)\n",
    "\n",
    "pd_meta = pd.DataFrame.from_dict(meta_df)\n",
    "pd_meta.to_csv(\"campaign_meta.csv\")\n",
    "pd_meta.to_csv(f\"Campaigns/{SITE}/campaign_meta.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b24d2f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-11-30T23:23:53.524Z"
    }
   },
   "outputs": [],
   "source": [
    "#US\n",
    "pd_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b530b6c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T21:57:34.620071Z",
     "start_time": "2022-11-30T21:57:34.620062Z"
    }
   },
   "outputs": [],
   "source": [
    "#CERN\n",
    "pd_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c910e7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-29T07:53:36.734514Z",
     "start_time": "2022-11-29T07:53:36.731764Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# df_replicas = spark.read.format('avro').load(HDFS_RUCIO_REPLICAS)\\\n",
    "#                     .withColumn('rse_id', F.lower(F.hex(F.col('RSE_ID'))))\\\n",
    "#                     .withColumnRenamed('NAME', 'file_name')\\\n",
    "#                     .alias(\"replicas\")\\\n",
    "#                     .join(\n",
    "#                         df_rses.alias(\"rse_name\"),\n",
    "#                         F.col(\"rse_name.rse_id\")==F.col(\"replicas.rse_id\")\n",
    "#                     )\\\n",
    "#                     .select(['replicas.rse_id',  'rse_name', 'file_name',])\n",
    "\n",
    "#Check the latest access for replica of miniaod(sim) in concern\n",
    "#We are ignoring last access - so skip this\n",
    "\n",
    "# df_locked_miniaods_us_with_last_access = df_locks_miniaod_us.alias(\"mini_lock\")\\\n",
    "#                                                             .join(df_replicas.alias(\"replicas\"),\n",
    "#                                                                   [F.col(\"replicas.file_name\")==F.col(\"mini_lock.file_name\"), F.col(\"replicas.rse_id\")==F.col(\"mini_lock.rse_id\")]\n",
    "#                                                                  )\\\n",
    "#                                                             .select([\"mini_lock.rse_name\", \"mini_lock.rse_id\", \"mini_lock.file_name\", \"mini_lock.file_size\", \"mini_lock.rule\", \"replicas.accessed_at\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bce9e22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-29T11:22:55.225019Z",
     "start_time": "2022-11-29T11:22:55.216342Z"
    }
   },
   "outputs": [],
   "source": [
    "print(pd_meta.to_markdown(tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbfc3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "1937379375612216/1e12"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "sparkconnect": {
   "bundled_options": [],
   "list_of_options": [
    {
     "name": "spark.jars.packages",
     "value": "org.apache.spark:spark-avro_2.12:3.2.1"
    },
    {
     "name": "spark.executor.memory",
     "value": "16g"
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
