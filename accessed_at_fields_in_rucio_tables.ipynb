{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72ca90b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T09:52:35.700283Z",
     "start_time": "2023-02-12T09:52:35.685194Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5118b6af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T09:52:36.167633Z",
     "start_time": "2023-02-12T09:52:36.162426Z"
    }
   },
   "outputs": [],
   "source": [
    "TODAY = (datetime.today() - timedelta(days=0)).strftime('%Y-%m-%d')\n",
    "\n",
    "HDFS_RUCIO_REPLICAS = f'/project/awg/cms/rucio/{TODAY}/replicas/part*.avro'\n",
    "HDFS_RUCIO_DIDS = f'/project/awg/cms/rucio/{TODAY}/dids/part*.avro'\n",
    "\n",
    "INT_MAX = 2147483647000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18432ec1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T09:52:36.644770Z",
     "start_time": "2023-02-12T09:52:36.637641Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_df_replicas(spark):\n",
    "    return spark.read.format('avro').load(HDFS_RUCIO_REPLICAS) \\\n",
    "        .filter(F.col('scope') == 'cms') \\\n",
    "        .withColumnRenamed('NAME', 'file_name') \\\n",
    "        .withColumnRenamed('ACCESSED_AT', 'rep_accessed_at') \\\n",
    "        .groupby(\"file_name\").agg(F.max(\"rep_accessed_at\").alias(\"max_rep_accessed_at\"))\\\n",
    "        .select(['file_name', 'max_rep_accessed_at'])\n",
    "\n",
    "\n",
    "def get_df_dids_files(spark):\n",
    "    return spark.read.format('avro').load(HDFS_RUCIO_DIDS) \\\n",
    "        .filter(F.col('DELETED_AT').isNull()) \\\n",
    "        .filter(F.col('HIDDEN') == '0') \\\n",
    "        .filter(F.col('SCOPE') == 'cms') \\\n",
    "        .filter(F.col('DID_TYPE') == 'F') \\\n",
    "        .withColumnRenamed('NAME', 'file_name') \\\n",
    "        .withColumnRenamed('ACCESSED_AT', 'dids_accessed_at') \\\n",
    "        .select(['file_name', 'dids_accessed_at'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c702043",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T09:52:46.276602Z",
     "start_time": "2023-02-12T09:52:37.384575Z"
    }
   },
   "outputs": [],
   "source": [
    "df_replicas = get_df_replicas(spark)\n",
    "df_dids = get_df_dids_files(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a74309a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T09:53:58.023411Z",
     "start_time": "2023-02-12T09:52:46.281286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid dates (set to INTMAX) in DIDs table: 186\n",
      "Invalid dates (set to INTMAX) in Replicas table: 476\n"
     ]
    }
   ],
   "source": [
    "#intmax timestamps in replicas and dids table\n",
    "dids_intmax = df_dids.filter(F.col(\"dids_accessed_at\")==INT_MAX).count()\n",
    "replicas_intmax = df_replicas.filter(F.col(\"max_rep_accessed_at\")==INT_MAX).count()\n",
    "\n",
    "print(f\"Invalid dates (set to INTMAX) in DIDs table: {dids_intmax}\")\n",
    "print(f\"Invalid dates (set to INTMAX) in Replicas table: {replicas_intmax}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff79f647",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T09:53:58.212895Z",
     "start_time": "2023-02-12T09:53:58.029166Z"
    }
   },
   "outputs": [],
   "source": [
    "df_accessed_at = df_replicas.join(df_dids, [\"file_name\"], \"inner\")\\\n",
    "                    .na.fill(0).withColumn(\"accessed_at_comparison\", \n",
    "                    F.when((F.col(\"dids_accessed_at\")+F.col(\"max_rep_accessed_at\")==0), \"Both None\")\\\n",
    "                     .when(F.col(\"dids_accessed_at\")<F.col(\"max_rep_accessed_at\"), \"dids_accessed_at SMALLER THAN max_rep_accessed_at\")\\\n",
    "                     .when(F.col(\"dids_accessed_at\")>F.col(\"max_rep_accessed_at\"), \"dids_accessed_at GREATER THAN max_rep_accessed_at\")\\\n",
    "                     .otherwise(\"Both Equal\")\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a42777cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T09:53:58.239868Z",
     "start_time": "2023-02-12T09:53:58.216677Z"
    }
   },
   "outputs": [],
   "source": [
    "df_summary = df_accessed_at.groupby(\"accessed_at_comparison\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6930af7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T09:54:39.565624Z",
     "start_time": "2023-02-12T09:53:58.242538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+--------+\n",
      "|accessed_at_comparison                           |count   |\n",
      "+-------------------------------------------------+--------+\n",
      "|dids_accessed_at GREATER THAN max_rep_accessed_at|10894086|\n",
      "|dids_accessed_at SMALLER THAN max_rep_accessed_at|265600  |\n",
      "|Both Equal                                       |10099428|\n",
      "|Both None                                        |65412557|\n",
      "+-------------------------------------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_summary.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5428ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "sparkconnect": {
   "bundled_options": [],
   "list_of_options": [
    {
     "name": "spark.jars.packages",
     "value": "org.apache.spark:spark-avro_2.12:3.2.1"
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
